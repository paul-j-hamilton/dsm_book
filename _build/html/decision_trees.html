
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>10.1. Decision Trees &#8212; Data Science for Managers</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="10.2. Random Forest" href="random_forest.html" />
    <link rel="prev" title="10. Tree Models" href="dt_rf.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science for Managers</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to Data Science for Managers!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="roadmap.html">
   Course Roadmap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="assignments.html">
   Assignment Sheets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="access.html">
   Access to Materials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="platforms.html">
   Coding Platforms
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  R Bootcamp
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="rbasics.html">
   R Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="r_as_a_calculator.html">
     R as a Calculator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="assignment.html">
     Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data_types.html">
     Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rbasics_quiz1.html">
     <strong>
      Quiz #1
     </strong>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="atomic_vectors.html">
     Atomic Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="functions.html">
     Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rbasics_quiz2.html">
     <strong>
      Quiz #2
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="dataframes.html">
   Data Frames
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="r_packages.html">
     R Packages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reading_in_data.html">
     Reading in Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data_frame_basics.html">
     Data Frame Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="df_basics_exercise.html">
     <strong>
      Exercise:
     </strong>
     Data Frame Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fixing_variable_types.html">
     Fixing Variable Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sorting_data.html">
     Sorting Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="filtering_rows.html">
     Filtering Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="selecting_columns.html">
     Selecting Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="df_manipulation_exercise.html">
     <strong>
      Exercise:
     </strong>
     Data Frame Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="df_manipulation_quiz.html">
     <strong>
      Quiz
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bootcamp_finish_message.html">
   Welcome to the Course!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Exploratory Data Analysis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="eda.html">
   1. Exploring Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="summary_stats.html">
     1.1. Summary Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="visualization.html">
     1.2. Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eda_quiz.html">
     1.3.
     <strong>
      Quiz
     </strong>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eda_case.html">
     1.4.
     <strong>
      Case Study:
     </strong>
     Sabermetrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ggplot.html">
     1.5. Visualization with ggplot (⚵)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="eda_tidyverse.html">
   2. Data Wrangling with the tidyverse
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="pipe_operator.html">
     2.1. The Pipe Operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="summarise.html">
     2.2. Summarising Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dds.html">
     2.3.
     <strong>
      Case Study:
     </strong>
     California Department of Developmental Services (DDS)
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="stat_inference.html">
   3. Statistical Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="samps_pops.html">
     3.1. Samples &amp; Populations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="conf_int.html">
     3.2. Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hyp_testing.html">
     3.3. Hypothesis Testing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="causal_inf.html">
   4. Causal Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="obs_studies.html">
     4.1. Observational Studies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rand_experiments.html">
     4.2. Randomized Experiments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="causal_exercise.html">
     4.3.
     <strong>
      Exercise:
     </strong>
     Causal Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="power.html">
     4.4. Power
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="linear_regression.html">
   5. Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="correlation.html">
     5.1. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="simple_reg.html">
     5.2. Simple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="understanding_reg.html">
     5.3. Understanding Our Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multiple_linear_regression.html">
     5.4. Multiple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dummy.html">
     5.5. Dummy Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="transformations.html">
     5.6. Transformations (⚵)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="interactions.html">
     5.7. Interactions (⚵)
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prediction &amp; Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ml_intro.html">
   6. Introduction to Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="logistic_reg.html">
   7. Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="why_not_lin.html">
     7.1. Why Not Linear Regression?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="simple_log_reg.html">
     7.2. Simple Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multiple_log_reg.html">
     7.3. Multiple Logistic Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="knn.html">
   8. k-Nearest Neighbors (kNN)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="bias_variance.html">
     8.4. The Bias-Variance Tradeoff
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="model_eval.html">
   9. Model Evaluation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="data_partition.html">
     9.1. Partitioning Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="performance_metrics.html">
     9.2. Performance Metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="dt_rf.html">
   10. Tree Models
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     10.1. Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="random_forest.html">
     10.2. Random Forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="xgboost.html">
     10.3. XGBoost (⚵)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="neural_nets.html">
   11. Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="unsupervised.html">
   12. Unsupervised Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nlp.html">
   13. Natural Language Processing
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/decision_trees.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/decision_trees.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fdecision_trees.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/decision_trees.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-trees">
   10.1.1. Classification Trees
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tuning-hyperparameters">
     10.1.1.1. Tuning Hyperparameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-trees">
   10.1.2. Regression Trees
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="decision-trees">
<h1><span class="section-number">10.1. </span>Decision Trees<a class="headerlink" href="#decision-trees" title="Permalink to this headline">¶</a></h1>
<p><strong>Classification and regression tree (CART) models</strong> are a popular class of machine learning algorithms that make predictions according to a set of logical rules learned from training data. Tree models that predict discrete outcomes are referred to as <strong>classification trees</strong>, while tree models that predict continuous outcomes are referred to as <strong>regression trees</strong>.</p>
<p>One major advantage of CART models is their interpretability. As we will see, CART models make predictions according to a series of logical rules that can be analyzed and understood by human users. This is in contrast to many other algorithms (like the random forest model discussed in the next section), which are more difficult to interpret.</p>
<div class="section" id="classification-trees">
<h2><span class="section-number">10.1.1. </span>Classification Trees<a class="headerlink" href="#classification-trees" title="Permalink to this headline">¶</a></h2>
<p>To understand classification trees, let’s start with a simplified version of our <code class="docutils literal notranslate"><span class="pre">churn</span></code> data set that only has twelve observations and two independent features, <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> and <code class="docutils literal notranslate"><span class="pre">account_length</span></code>. Our feature space looks as follows:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parsed with column specification:
cols(
  account_length = col_double(),
  total_intl_charge = col_double(),
  churn = col_double()
)
</pre></div>
</div>
<img alt="_images/decision_trees_2_1.png" src="_images/decision_trees_2_1.png" />
</div>
</div>
<p>The classification tree algorithm works by drawing a straight line that partitions the feature space to maximize the homogeneity (or minimize the entropy) of each sub-region. For example, imagine we drew a vertical line at around <code class="docutils literal notranslate"><span class="pre">account_length</span></code> = 87, dividing the feature space into <strong>R1</strong> and <strong>R2</strong>. Intuitively, R2 is completely homogeneous because it only contains observations with the same outcome—“no churn”. R1 is less homogeneous because it contains two “churn” observations and one “no churn” observation.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parsed with column specification:
cols(
  account_length = col_double(),
  total_intl_charge = col_double(),
  churn = col_double()
)
</pre></div>
</div>
<img alt="_images/decision_trees_4_1.png" src="_images/decision_trees_4_1.png" />
</div>
</div>
<p>In this simple example we made cuts based on a visual inspection of the data, but the classification tree algorithm uses a measure known as <strong>entropy</strong> to ensure that each cut maximizes the homogeneity of the resulting subspaces. Entropy is defined as follows:</p>
<div class="math notranslate nohighlight">
\[Entropy = -\sum_i^C{p_ilog(p_i)}\]</div>
<p>where the data set has <span class="math notranslate nohighlight">\(C\)</span> classes (or unique outcome values), and <span class="math notranslate nohighlight">\(p_i\)</span> represents the proportion of observations in the data from the <span class="math notranslate nohighlight">\(i\)</span>th class. In our case <span class="math notranslate nohighlight">\(C=2\)</span> because we have two classes: “churn” and “no churn”. Notice, this is very similar to the log loss formula that we introduced in Section &#64;ref(log-loss).</p>
<p>Using this formula, we can first calculate the entropy of our original data set (before we made any cuts), which we’ll call <span class="math notranslate nohighlight">\(E_0\)</span>. There are two “churn” customers and ten “no churn” customers, so the entropy is:</p>
<div class="math notranslate nohighlight">
\[E_0 = -[\frac{2}{12}log(\frac{2}{12}) + \frac{10}{12}log(\frac{10}{12})] = 0.1957\]</div>
<p>Now we will calculate the entropy after making the cut, for each subspace separately. The subspace <strong>R2</strong> is completely homogeneous (all nine customers are “no churn”), so the entropy equals zero:</p>
<div class="math notranslate nohighlight">
\[E_{R2} = -[\frac{9}{9}log(\frac{9}{9})] = 0\]</div>
<p>The subspace <span class="math notranslate nohighlight">\(R1\)</span> has one “no churn” and two “churns”, so the entropy equals:</p>
<div class="math notranslate nohighlight">
\[E_{R1} = -[\frac{2}{3}log(\frac{2}{3}) + \frac{1}{3}log(\frac{1}{3})] = 0.2764\]</div>
<p>To calculate the overall entropy after making the cut at <code class="docutils literal notranslate"><span class="pre">account_length</span></code> = 87, we take a weighted average of <span class="math notranslate nohighlight">\(E_{R1}\)</span> and <span class="math notranslate nohighlight">\(E_{R2}\)</span> based on the number of observations in each subspace:</p>
<div class="math notranslate nohighlight">
\[E_{Cut1} = \frac{3}{12}E_{R1} + \frac{9}{12}E_{R2} = 0.0691\]</div>
<p>The <strong>information gain</strong>, or the reduction in entropy due to this cut, is then:
$<span class="math notranslate nohighlight">\(E_0 - E_{Cut1} = 0.1957 - 0.0691 = 0.1266\)</span>$</p>
<p>Each cut is made at the point that will result in the greatest reduction in the information gain. To further reduce the entropy of <strong>R1</strong>, we can make a cut around <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> = 3.8 to partition <strong>R1</strong> into two smaller regions (<strong>R3</strong> and <strong>R4</strong>) that are completely homogeneous. Because the feature space is completely divided into pure regions, the entropy after the second cut is zero:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}E_{Cut2} &amp; = \frac{9}{12}E_{R2} + \frac{2}{12}E_{R3} + \frac{1}{12}E_{R4} \\ &amp; = \frac{9}{12}(0) + \frac{2}{12}(0) + \frac{1}{12}(0) \\ &amp; = 0
\end{aligned}\end{split}\]</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parsed with column specification:
cols(
  account_length = col_double(),
  total_intl_charge = col_double(),
  churn = col_double()
)
</pre></div>
</div>
<img alt="_images/decision_trees_6_1.png" src="_images/decision_trees_6_1.png" />
</div>
</div>
<p>Because each subspace is completely pure, there are no additional cuts we could make to further reduce the entropy.</p>
<p>To create pure feature space, we first made a cut at <code class="docutils literal notranslate"><span class="pre">account_length</span></code> = 87, then within the region where <code class="docutils literal notranslate"><span class="pre">account_length</span></code> was less than 87 made an additional cut at <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> = 3.8.  From this we can write out a set of decision rules:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/decision_trees_8_0.png" src="_images/decision_trees_8_0.png" />
</div>
</div>
<p>We can use this decision tree to predict whether or not a new observation will churn. For example:</p>
<ul class="simple">
<li><p>If a new observation has an <code class="docutils literal notranslate"><span class="pre">account_length</span></code> greater than or equal to 87, we move down the left branch of the tree and predict “no churn”.</p></li>
<li><p>If a new observation has an <code class="docutils literal notranslate"><span class="pre">account_length</span></code> less than 87 and a <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> greater than or equal to 3.8, we would move right at the first split and left at the second split of the tree, leading to a prediction of “no churn”.</p></li>
<li><p>If a new observation has an <code class="docutils literal notranslate"><span class="pre">account_length</span></code> less than 87 and a <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> less than 3.8, we would move right at the first split and right at the second split of the tree, leading to a prediction of “churn”.</p></li>
</ul>
<p>How do we interpret the numbers shown in the tree? In the plot each node has three rows, showing (in order):</p>
<ul class="simple">
<li><p>The majority class in that node (“churn” / “no churn”).</p></li>
<li><p>The proportion of the observations in that node that churned.</p></li>
<li><p>The percentage of the total data inside that node.</p></li>
</ul>
<p>For example, let’s start at the top node, which represents the data set before any cuts have been made. Because no cuts have been made, this node includes all of the data, so the third line shows 100%. Of the twelve observations in the data set, two of them churned, so the proportion of observations that churned equals (2 / 12) <span class="math notranslate nohighlight">\(\approx\)</span> 0.17. Because this proportion is lower than the default cutoff of 0.5, the majority class for this node is “no churn”.</p>
<p>Now imagine what happens as we work our way down the tree. If <code class="docutils literal notranslate"><span class="pre">account_length</span></code> is greater than or equal to 87 we move to the left branch. This corresponds to the subspace R2 in the plot of the feature space. This subspace contains nine observations, or 75% of the total observations in the data set ((9 / 12) = 75%). None of these observations churned, so the second line in the node is 0.00, and the majority class is “no churn”.</p>
<p>Now imagine we work our way down the right branch of the tree. If <code class="docutils literal notranslate"><span class="pre">account_length</span></code> is less than 87, we move into the subspace R1. R1 has three observations ((3 / 12) = 25%), two of which churned ((2 / 3) <span class="math notranslate nohighlight">\(\approx\)</span> 0.67). From this node, if <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> is less than 3.8 we move to the right, which represents subspace R3. Here we have two observations ((2 / 12) <span class="math notranslate nohighlight">\(\approx\)</span> 17%), both of which churned ((2 / 2) = 1.00). If instead <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> is greater than or equal to 3.8 we move to the left, which represents subspace R4. Here we have one observation ((1 / 12) <span class="math notranslate nohighlight">\(\approx\)</span> 8%), which did not churn ((0 / 1) = 0.00).</p>
<p>In R, we can fit a classification tree to our data using the <code class="docutils literal notranslate"><span class="pre">rpart()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">rpart</span></code> package. This function uses the following syntax:</p>
<div class="admonition-syntax admonition">
<p class="admonition-title">Syntax</p>
<p><code class="docutils literal notranslate"><span class="pre">rpart::rpart(y</span> <span class="pre">~</span> <span class="pre">x1</span> <span class="pre">+</span> <span class="pre">x2</span> <span class="pre">+</span> <span class="pre">...</span> <span class="pre">+</span> <span class="pre">xp,</span> <span class="pre">data,</span> <span class="pre">maxdepth</span> <span class="pre">=</span> <span class="pre">30)</span></code></p>
<ul class="simple">
<li><p><em>Required arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code>: The name of the dependent (<span class="math notranslate nohighlight">\(Y\)</span>) variable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x1</span></code>, <code class="docutils literal notranslate"><span class="pre">x2</span></code>, … <code class="docutils literal notranslate"><span class="pre">xp</span></code>: The name of the first, second, and <span class="math notranslate nohighlight">\(pth\)</span> independent variables.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: The name of the data frame with the <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">x1</span></code>, <code class="docutils literal notranslate"><span class="pre">x2</span></code>, and <code class="docutils literal notranslate"><span class="pre">xp</span></code> variables.</p></li>
</ul>
</li>
<li><p><em>Optional arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">maxdepth</span></code>: The maximum depth of the tree (see Section &#64;ref(tuning-hyperparameters-cart)).</p></li>
</ul>
</li>
</ul>
</div>
<p>Then, after we have built a model with <code class="docutils literal notranslate"><span class="pre">rpart()</span></code>, we can visualize the tree with the <code class="docutils literal notranslate"><span class="pre">rpart.plot()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">rpart.plot</span></code> package:</p>
<div class="admonition-syntax admonition">
<p class="admonition-title">Syntax</p>
<p><code class="docutils literal notranslate"><span class="pre">rpart.plot::rpart.plot(x)</span></code></p>
<ul class="simple">
<li><p><em>Required arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">x</span></code>: A tree model built with <code class="docutils literal notranslate"><span class="pre">rpart()</span></code>.</p></li>
</ul>
</li>
</ul>
</div>
<p>Below we apply these functions to our full <code class="docutils literal notranslate"><span class="pre">churn</span></code> data set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">&lt;-</span> <span class="nf">rpart</span><span class="p">(</span><span class="n">churn</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">churn</span><span class="p">)</span>
<span class="nf">rpart.plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_trees_10_0.png" src="_images/decision_trees_10_0.png" />
</div>
</div>
<div class="section" id="tuning-hyperparameters">
<h3><span class="section-number">10.1.1.1. </span>Tuning Hyperparameters<a class="headerlink" href="#tuning-hyperparameters" title="Permalink to this headline">¶</a></h3>
<p>Let’s return to the simplified data set from the previous section, with only twelve observations and two features. After inspecting the classification tree we built from this data, you may suspect that something is wrong with the right branch - customers with a higher <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> are classified as “no churn”, while customers with a lower <code class="docutils literal notranslate"><span class="pre">total_intl_charge</span></code> are classified as “churn”. Based on the context of the business we may find this pattern surprising, as we expect customers with high international charges to be <em>more</em> likely to switch services. One possibility is that we are overfitting the data, so the decision tree is picking up on the noise in the sample instead of the signal.</p>
<p>To prevent overfitting, we can <strong>prune</strong> the decision tree to a certain depth; or, in other words, limit how many cuts we can perform. For example, let us prune this tree to a depth of one, meaning the algorithm cannot make more than one cut. The resulting pruned tree is shown below. Under this set of rules, customers with an <code class="docutils literal notranslate"><span class="pre">account_length</span></code> greater than or equal to 87 are classified as “no churn”; this is because subspace R2 (which represents <code class="docutils literal notranslate"><span class="pre">account_length</span></code> &gt;= 87) contains only “no churn” observations. Customers with an <code class="docutils literal notranslate"><span class="pre">account_length</span></code> less than 87 are assigned a probability of churning of 0.67; this is because subspace R1 (which represents <code class="docutils literal notranslate"><span class="pre">account_length</span></code> &lt; 87) contains two “churn” observations and one “no churn” observation ((2 / 3) <span class="math notranslate nohighlight">\(\approx\)</span> 0.67).</p>
<p>For CART models, the <strong>depth</strong> hyperparameter serves a similar purpose as the <span class="math notranslate nohighlight">\(k_{knn}\)</span> hyperparameter for the kNN algorithm. By tuning the value of the tree’s depth, we seek to balance the bias-variance tradeoff. If the depth is too large, our tree will grow too deep and overfit the training data. Conversely, if the depth is too small, our tree will not grow deep enough and will underfit the training data. Therefore, we need to use cross validation to identify the value of depth that balances this tradeoff on our data.</p>
<p>In R, we can tune the depth hyperparameter through cross validation using the exact same functions shown in the previous chapter. To train a cross-validated classification tree, we can use the <code class="docutils literal notranslate"><span class="pre">train()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">caret</span></code> package just as we did in the previous chapter (Section &#64;ref(k-fold-cross-validation)). To apply this function with the classification tree algorithm:</p>
<ul class="simple">
<li><p>As before, we specify the independent and dependent variables in our model using the tilde (<code class="docutils literal notranslate"><span class="pre">~</span></code>). Remember that if you just replace the names of the features with the wildcard character <code class="docutils literal notranslate"><span class="pre">.</span></code>, the model will be built using all of the features in the data set.</p></li>
<li><p>Because the classification tree algorithm does not require the data to be normalized like kNN, we can pass in the data set <code class="docutils literal notranslate"><span class="pre">churn</span></code> instead of <code class="docutils literal notranslate"><span class="pre">churnScaled</span></code>.</p></li>
<li><p>To apply the classification tree algorithm, we set the <code class="docutils literal notranslate"><span class="pre">method</span></code> argument equal to <code class="docutils literal notranslate"><span class="pre">&quot;rpart2&quot;</span></code>.</p></li>
<li><p>Recall that in Section &#64;ref(<span class="math notranslate nohighlight">\(k\)</span>-fold-cross-validation) we created an object called <code class="docutils literal notranslate"><span class="pre">cvConditions</span></code>, which is used to ensure that for each model we test, the cross validation process is performed consistently. We can re-use that object here so we can directly compare these results to the results from the kNN model.</p></li>
</ul>
<p>By default, the <code class="docutils literal notranslate"><span class="pre">train()</span></code> function comes up with a grid of different hyperparameter values to test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">972945</span><span class="p">)</span>
<span class="n">rpartCV</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">churn</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> 
                 <span class="n">data</span> <span class="o">=</span> <span class="n">churn</span><span class="p">,</span>
                 <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;rpart2&quot;</span><span class="p">,</span> 
                 <span class="n">trControl</span> <span class="o">=</span> <span class="n">cvConditions</span><span class="p">)</span>

<span class="n">rpartCV</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CART 

3400 samples
  12 predictor
   2 classes: &#39;no&#39;, &#39;yes&#39; 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2720, 2720, 2719, 2720, 2721 
Resampling results across tuning parameters:

  maxdepth  Accuracy   Kappa    
  1         0.8720613  0.3290213
  2         0.8823554  0.3917376
  4         0.9161777  0.5991045

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was maxdepth = 4.
</pre></div>
</div>
</div>
</div>
<p>Based on these results the optimal value of <code class="docutils literal notranslate"><span class="pre">maxdepth</span></code> is four, so our final tree will be pruned to a depth of four. We can visualize this tree by applying the <code class="docutils literal notranslate"><span class="pre">rpart.plot()</span></code> function to <code class="docutils literal notranslate"><span class="pre">rpartCV$finalModel</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">rpart.plot</span><span class="p">(</span><span class="n">rpartCV</span><span class="o">$</span><span class="n">finalModel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_trees_16_0.png" src="_images/decision_trees_16_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="regression-trees">
<h2><span class="section-number">10.1.2. </span>Regression Trees<a class="headerlink" href="#regression-trees" title="Permalink to this headline">¶</a></h2>
<p>[In Progress]</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            kernelName: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="dt_rf.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">10. </span>Tree Models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="random_forest.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">10.2. </span>Random Forest</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By DSM Faculty<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>