
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>9.1. Partitioning Data &#8212; Data Science for Managers</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9.2. Performance Metrics" href="performance_metrics.html" />
    <link rel="prev" title="9. Model Evaluation" href="model_eval.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science for Managers</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to Data Science for Managers!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_getting_started/roadmap.html">
   Course Roadmap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_getting_started/assignments.html">
   Assignment Sheets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_getting_started/access.html">
   Access to Materials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_getting_started/platforms.html">
   Coding Platforms
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  R Bootcamp
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../00_bootcamp/01_rbasics/rbasics.html">
   R Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/01_rbasics/r_as_a_calculator.html">
     R as a Calculator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/01_rbasics/assignment.html">
     Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/01_rbasics/data_types.html">
     Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/01_rbasics/rbasics_quiz1.html">
     <strong>
      Quiz #1
     </strong>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/01_rbasics/atomic_vectors.html">
     Atomic Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/01_rbasics/functions.html">
     Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/01_rbasics/rbasics_quiz2.html">
     <strong>
      Quiz #2
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../00_bootcamp/02_dataframes/dataframes.html">
   Data Frames
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/r_packages.html">
     R Packages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/reading_in_data.html">
     Reading in Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/data_frame_basics.html">
     Data Frame Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/df_basics_exercise.html">
     <strong>
      Exercise:
     </strong>
     Data Frame Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/fixing_variable_types.html">
     Fixing Variable Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/sorting_data.html">
     Sorting Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/filtering_rows.html">
     Filtering Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/selecting_columns.html">
     Selecting Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/df_manipulation_exercise.html">
     <strong>
      Exercise:
     </strong>
     Data Frame Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_bootcamp/02_dataframes/df_manipulation_quiz.html">
     <strong>
      Quiz
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_bootcamp/bootcamp_finish_message.html">
   Welcome to the Course!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Exploratory Data Analysis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01_eda/eda.html">
   1. Exploring Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_eda/summary_stats.html">
     1.1. Summary Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_eda/visualization.html">
     1.2. Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_eda/eda_quiz.html">
     1.3.
     <strong>
      Quiz
     </strong>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_eda/ggplot.html">
     1.4. Visualization with ggplot (⚵)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02_tidy/eda_tidyverse.html">
   2. Data Wrangling with the tidyverse
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_tidy/pipe_operator.html">
     2.1. The Pipe Operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_tidy/summarise.html">
     2.2. Summarising Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_tidy/dds.html">
     2.3.
     <strong>
      Case Study:
     </strong>
     California Department of Developmental Services (DDS)
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03_stat_inference/stat_inference.html">
   3. Statistical Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_stat_inference/samps_pops.html">
     3.1. Samples &amp; Populations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_stat_inference/conf_int.html">
     3.2. Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_stat_inference/hyp_testing.html">
     3.3. Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_stat_inference/hyp_test_quiz.html">
     3.4.
     <strong>
      Quiz
     </strong>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_stat_inference/one_samp_test_exercise.html">
     3.5.
     <strong>
      Exercise:
     </strong>
     One-Sample Hypothesis Testing (⚵)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_stat_inference/two_samp_test_exercise.html">
     3.6.
     <strong>
      Exercise:
     </strong>
     Two-Sample Hypothesis Testing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04_causal_inference/causal_inference.html">
   4. Causal Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_causal_inference/obs_studies.html">
     4.1. Observational Studies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_causal_inference/rand_experiments.html">
     4.2. Randomized Experiments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_causal_inference/causal_exercise.html">
     4.3.
     <strong>
      Exercise:
     </strong>
     Causal Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_causal_inference/power.html">
     4.4. Power
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05_linear_regression/linear_regression.html">
   5. Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/correlation.html">
     5.1. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/simple_reg.html">
     5.2. Simple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/understanding_reg.html">
     5.3. Understanding Our Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/reg_exercise1.html">
     5.4.
     <strong>
      Exercise:
     </strong>
     Simple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/multiple_linear_regression.html">
     5.5. Multiple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/dummy.html">
     5.6. Dummy Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/reg_exercise2.html">
     5.7.
     <strong>
      Exercise:
     </strong>
     Interactions (⚵)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/transformations.html">
     5.8. Transformations (⚵)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/interactions.html">
     5.9. Interactions (⚵)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_linear_regression/reg_exercise3.html">
     5.10.
     <strong>
      Exercise:
     </strong>
     Multiple Linear Regression
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prediction &amp; Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../06_ml_intro/ml_intro.html">
   6. Introduction to Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07_logistic_regression/logistic_regression.html">
   7. Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07_logistic_regression/why_not_lin.html">
     7.1. Why Not Linear Regression?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07_logistic_regression/simple_log_reg.html">
     7.2. Simple Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07_logistic_regression/multiple_log_reg.html">
     7.3. Multiple Logistic Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08_knn/knn.html">
   8. k-Nearest Neighbors (kNN)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08_knn/bias_variance.html">
     8.4. The Bias-Variance Tradeoff
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="model_eval.html">
   9. Model Evaluation
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     9.1. Partitioning Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="performance_metrics.html">
     9.2. Performance Metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10_dt_rf/dt_rf.html">
   10. Tree Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_dt_rf/decision_trees.html">
     10.1. Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_dt_rf/random_forest.html">
     10.2. Random Forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10_dt_rf/xgboost.html">
     10.3. XGBoost (⚵)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../11_neural_nets/neural_nets.html">
   11. Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../12_unsupervised/unsupervised.html">
   12. Unsupervised Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../13_nlp/nlp.html">
   13. Natural Language Processing
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/09_model_eval/data_partition.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/09_model_eval/data_partition.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F09_model_eval/data_partition.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/09_model_eval/data_partition.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-validation-sets">
   9.1.1. Train &amp; Validation Sets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-fold-cross-validation">
   9.1.2.
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Fold Cross Validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#holdout-sets">
   9.1.3. Holdout Sets
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="partitioning-data">
<h1><span class="section-number">9.1. </span>Partitioning Data<a class="headerlink" href="#partitioning-data" title="Permalink to this headline">¶</a></h1>
<div class="section" id="train-validation-sets">
<h2><span class="section-number">9.1.1. </span>Train &amp; Validation Sets<a class="headerlink" href="#train-validation-sets" title="Permalink to this headline">¶</a></h2>
<p>Let’s return to the kNN model we applied to the <code class="docutils literal notranslate"><span class="pre">churn</span></code> data in the previous chapter. In order to traverse the bias-variance tradeoff, we need to <strong>tune</strong> the model hyperparameter <span class="math notranslate nohighlight">\(k\)</span>. If <span class="math notranslate nohighlight">\(k\)</span> is too small we risk overfitting the data and picking up on the noise of the sample, while if <span class="math notranslate nohighlight">\(k\)</span> is too large we risk underfitting the data and missing the signal. Consequently, we need to find the value of <span class="math notranslate nohighlight">\(k\)</span> that maximizes the ability of the model to make accurate predictions on unseen data.</p>
<p>A typical approach to this problem is to split the data into a training set and a validation set. One rule of thumb is to devote 80% of the available data to the training set, and 20% to the validation set. The <strong>training set</strong> is used to build models with different values of our hyperparameter <span class="math notranslate nohighlight">\(k\)</span>. We start by defining a <strong>grid</strong> of different values for the hyperparameter that we want to test. In this case, our grid will be <span class="math notranslate nohighlight">\(k = {1, 3, 5, 10, 20}\)</span>. We then use the training set to build five different models, each with a different value of <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Next, we apply all five of those models to the <strong>validation set</strong>, which is used to compare the accuracy of different models. Whichever value of <span class="math notranslate nohighlight">\(k\)</span> results in the most accurate predictions on the validation set is taken to be the optimal value.</p>
<p>Note that instead of using a validation set, we could just calculate the accuracy of each model on the training data. In other words, we could build a model on the training set, then calculate the accuracy of that model on the same data it was trained on. The reason one should never do this is that it will almost certainly result in overfitting. On the training set, the most accurate model is the one where <span class="math notranslate nohighlight">\(k\)</span> equals one, as this model very closely fits the training data. However, this model will not generalize well to unseen data. Therefore, we need the validation set to ensure that our model is not overfitting the training data, and that it will generalize well to new data.</p>
<p>We can split our processed data set (<code class="docutils literal notranslate"><span class="pre">churnScaled</span></code>) into training and validation sets using the <code class="docutils literal notranslate"><span class="pre">sample.split()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">caTools</span></code> package. One advantage of using <code class="docutils literal notranslate"><span class="pre">sample.split()</span></code> is that it ensures that the training and validation sets have the same proportions of the target feature, in our case <code class="docutils literal notranslate"><span class="pre">churn</span></code>.</p>
<p>Note that we are <em>randomly</em> dividing the data, meaning that each observation should have a chance of being included in the training set and a chance of being included in the validation set. We want this sampling process to be random, but we also want to ensure that every time the code is run, the same observations are sorted into the training set and the same observations are sorted into the validation set. This will guarantee that every time the code is re-run, we have the exact same training and validation sets. If we did not do this, two different runs of the code would almost certainly have a different set of observations in the training set, so the results would be different each time.</p>
<p>We can ensure that a random process is stable (<em>i.e.</em>, leads to the same result) by setting the random seed with <code class="docutils literal notranslate"><span class="pre">set.seed()</span></code>. The number you pass into this function “seeds” the randomization that R uses to split the data, so two people using the same random seed will have identical splits of the data. In the code below we use a random seed of <code class="docutils literal notranslate"><span class="pre">972941</span></code>, a number which was itself randomly chosen.</p>
<p>After setting the random seed we then apply <code class="docutils literal notranslate"><span class="pre">sample.split()</span></code>, which uses the following syntax:</p>
<div class="admonition-syntax admonition">
<p class="admonition-title">Syntax</p>
<p><code class="docutils literal notranslate"><span class="pre">caTools::sample.split(Y,</span> <span class="pre">SplitRatio</span> <span class="pre">=</span> <span class="pre">2/3)</span></code></p>
<ul class="simple">
<li><p><em>Required arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Y</span></code>: An atomic vector with the values of the target feature in the data set.</p></li>
</ul>
</li>
<li><p><em>Optional arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">SplitRatio</span></code>: The proportion of observations to use for the training set. The remaining observations are used for the validation set.</p></li>
</ul>
</li>
</ul>
</div>
<p>We save the output of <code class="docutils literal notranslate"><span class="pre">sample.split()</span></code> into <code class="docutils literal notranslate"><span class="pre">sample</span></code>, a vector with either <code class="docutils literal notranslate"><span class="pre">TRUE</span></code> or <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> for each observation in our data set. An element of <code class="docutils literal notranslate"><span class="pre">sample</span></code> is set equal to <code class="docutils literal notranslate"><span class="pre">TRUE</span></code> if the observation is assigned to the training set and <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> if the observation is assigned to the validation set. We can then create the two separate data sets <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">validate</span></code> using the <code class="docutils literal notranslate"><span class="pre">subset()</span></code> function. Note that we will place 80% of the data into the training set and 20% into the validation set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the random seed</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">972943</span><span class="p">)</span>

<span class="c1"># Define the training and validation sets</span>
<span class="nf">library</span><span class="p">(</span><span class="n">caTools</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">&lt;-</span> <span class="nf">sample.split</span><span class="p">(</span><span class="n">churnScaled</span><span class="o">$</span><span class="n">churn</span><span class="p">,</span> <span class="n">SplitRatio</span> <span class="o">=</span> <span class="m">0.8</span><span class="p">)</span>

<span class="c1"># Split the data into two data frames</span>
<span class="n">train</span> <span class="o">&lt;-</span> <span class="nf">subset</span><span class="p">(</span><span class="n">churnScaled</span><span class="p">,</span> <span class="n">sample</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="n">validate</span> <span class="o">&lt;-</span> <span class="nf">subset</span><span class="p">(</span><span class="n">churnScaled</span><span class="p">,</span> <span class="n">sample</span> <span class="o">==</span> <span class="kc">FALSE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning message:
&quot;package &#39;caTools&#39; was built under R version 3.6.3&quot;
</pre></div>
</div>
</div>
</div>
<p>If we view the dimensions of <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">validate</span></code>, we can see that <code class="docutils literal notranslate"><span class="pre">train</span></code> contains 80% of the observations and <code class="docutils literal notranslate"><span class="pre">validate</span></code> contains 20%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">dim</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="nf">dim</span><span class="p">(</span><span class="n">validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><ol class=list-inline>
	<li>2720</li>
	<li>13</li>
</ol>
</div><div class="output text_html"><ol class=list-inline>
	<li>680</li>
	<li>13</li>
</ol>
</div></div>
</div>
<p>Now we can use <code class="docutils literal notranslate"><span class="pre">train</span></code> to build five different models, each with a different value of <span class="math notranslate nohighlight">\(k\)</span>. We can then calculate the accuracy of those models on <code class="docutils literal notranslate"><span class="pre">validate</span></code> to determine the optimal value of <span class="math notranslate nohighlight">\(k\)</span>. In the code below, we fit all five of these models using the <code class="docutils literal notranslate"><span class="pre">knn()</span></code> function. Note that we set the <code class="docutils literal notranslate"><span class="pre">test</span></code> parameter equal to <code class="docutils literal notranslate"><span class="pre">validate</span></code> so that the models are applied to the validation set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">knnModelK1</span> <span class="o">&lt;-</span> <span class="nf">knn</span><span class="p">(</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> <span class="n">test</span> <span class="o">=</span> <span class="n">validate</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> 
                  <span class="n">cl</span> <span class="o">=</span> <span class="n">train</span><span class="o">$</span><span class="n">churn</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>

<span class="n">knnModelK3</span> <span class="o">&lt;-</span> <span class="nf">knn</span><span class="p">(</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> <span class="n">test</span> <span class="o">=</span> <span class="n">validate</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> 
                  <span class="n">cl</span> <span class="o">=</span> <span class="n">train</span><span class="o">$</span><span class="n">churn</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="m">3</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>

<span class="n">knnModelK5</span> <span class="o">&lt;-</span> <span class="nf">knn</span><span class="p">(</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> <span class="n">test</span> <span class="o">=</span> <span class="n">validate</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> 
                  <span class="n">cl</span> <span class="o">=</span> <span class="n">train</span><span class="o">$</span><span class="n">churn</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="m">5</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>

<span class="n">knnModelK10</span> <span class="o">&lt;-</span> <span class="nf">knn</span><span class="p">(</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> <span class="n">test</span> <span class="o">=</span> <span class="n">validate</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> 
                  <span class="n">cl</span> <span class="o">=</span> <span class="n">train</span><span class="o">$</span><span class="n">churn</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="m">10</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>

<span class="n">knnModelK20</span> <span class="o">&lt;-</span> <span class="nf">knn</span><span class="p">(</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> <span class="n">test</span> <span class="o">=</span> <span class="n">validate</span><span class="p">[,</span><span class="m">-13</span><span class="p">],</span> 
                  <span class="n">cl</span> <span class="o">=</span> <span class="n">train</span><span class="o">$</span><span class="n">churn</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="m">20</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To determine the performance of each model on the validation set, we need to compare the model’s predictions against the known, true values. Here we will score the models using <strong>accuracy</strong>, or the proportion of observations where the model’s prediction was correct. In Section <a class="reference external" href="performance_metrics.html#performance-metrics">Performance Metrics</a>, we will learn about other metrics that can be used to assess model performance.</p>
<p>We can easily calculate the accuracy of our models on the validation set using the <code class="docutils literal notranslate"><span class="pre">Accuracy()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">MLmetrics</span></code> package, which uses the following syntax:</p>
<div class="admonition-syntax admonition">
<p class="admonition-title">Syntax</p>
<p><code class="docutils literal notranslate"><span class="pre">MLmetrics::Accuracy(y_pred,</span> <span class="pre">y_true)</span></code></p>
<ul class="simple">
<li><p><em>Required arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">y_pred</span></code>: An atomic vector with the model predictions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">y_true</span></code>: An atomic vector with the true labels.</p></li>
</ul>
</li>
</ul>
</div>
<p>The model objects that we created (<em>e.g.</em>, <code class="docutils literal notranslate"><span class="pre">knnModelK1</span></code>) store a vector of the model’s predictions on the validation set. For example, if we display the first few elements of <code class="docutils literal notranslate"><span class="pre">knnModelK1</span></code>, we see the model’s prediction for the first few observations in <code class="docutils literal notranslate"><span class="pre">validate</span></code>. In this case, the model predicted that four of the five observations will not churn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">knnModelK1</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><ol class=list-inline>
	<li>no</li>
	<li>no</li>
	<li>no</li>
	<li>yes</li>
	<li>no</li>
</ol>

<details>
	<summary style=display:list-item;cursor:pointer>
		<strong>Levels</strong>:
	</summary>
	<ol class=list-inline>
		<li>'no'</li>
		<li>'yes'</li>
	</ol>
</details></div></div>
</div>
<p>To use <code class="docutils literal notranslate"><span class="pre">Accuracy()</span></code>, we pass in our vector of model predictions as <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> and the true values (stored in the column <code class="docutils literal notranslate"><span class="pre">validate$churn</span></code>) as <code class="docutils literal notranslate"><span class="pre">y_true</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">Accuracy</span><span class="p">(</span><span class="n">knnModelK1</span><span class="p">,</span> <span class="n">validate</span><span class="o">$</span><span class="n">churn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.854411764705882</div></div>
</div>
<p>This means that the model where <span class="math notranslate nohighlight">\(k\)</span> was one correctly predicted 85.44% of the observations in the validation set. Now let’s apply this to the other models:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">Accuracy</span><span class="p">(</span><span class="n">knnModelK3</span><span class="p">,</span> <span class="n">validate</span><span class="o">$</span><span class="n">churn</span><span class="p">)</span>
<span class="nf">Accuracy</span><span class="p">(</span><span class="n">knnModelK5</span><span class="p">,</span> <span class="n">validate</span><span class="o">$</span><span class="n">churn</span><span class="p">)</span>
<span class="nf">Accuracy</span><span class="p">(</span><span class="n">knnModelK10</span><span class="p">,</span> <span class="n">validate</span><span class="o">$</span><span class="n">churn</span><span class="p">)</span>
<span class="nf">Accuracy</span><span class="p">(</span><span class="n">knnModelK20</span><span class="p">,</span> <span class="n">validate</span><span class="o">$</span><span class="n">churn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.883823529411765</div><div class="output text_html">0.883823529411765</div><div class="output text_html">0.873529411764706</div><div class="output text_html">0.876470588235294</div></div>
</div>
<p>Based on these results, we can conclude that the best value for <span class="math notranslate nohighlight">\(k\)</span> is somewhere around three to five. We will use a <span class="math notranslate nohighlight">\(k\)</span> of three because it tied for the highest accuracy on the validation set.</p>
<p>Now that we have chosen a value for <span class="math notranslate nohighlight">\(k\)</span>, we would fit a final model with <span class="math notranslate nohighlight">\(k\)</span> equals three using all of the available data (<em>i.e.</em>, the combined training and validation sets, which is stored in <code class="docutils literal notranslate"><span class="pre">churnScaled</span></code>). This is the model we would deploy to predict which customers will churn in the upcoming quarter.</p>
</div>
<div class="section" id="k-fold-cross-validation">
<h2><span class="section-number">9.1.2. </span><span class="math notranslate nohighlight">\(k\)</span>-Fold Cross Validation<a class="headerlink" href="#k-fold-cross-validation" title="Permalink to this headline">¶</a></h2>
<p>Although we can help prevent overfitting by dividing our data into train and validation sets, this method is not without its shortcomings. It requires that we sacrifice a significant portion of our data (usually around 20%) for model validation, so we can only build our models on 80% of the data. We always want to build our models with as much data as possible, and this becomes especially problematic when working with smaller data sets.</p>
<p>An alternative method for training and validating different models is called <strong><span class="math notranslate nohighlight">\(k\)</span>-fold cross validation</strong>. Note that this <span class="math notranslate nohighlight">\(k\)</span> is unrelated to the hyperparameter <span class="math notranslate nohighlight">\(k\)</span> from the kNN algorithm; to distinguish between them, moving forward we will use <span class="math notranslate nohighlight">\(k_{fold}\)</span> when discussing cross validation, and <span class="math notranslate nohighlight">\(k_{knn}\)</span> when discussing the kNN algorithm. Cross validation randomly divides our data set into <span class="math notranslate nohighlight">\(k_{fold}\)</span> partitions (called folds). It then builds a model on all but one of these folds, and uses the held-out fold to validate that model’s predictive ability. It then repeats this procedure <span class="math notranslate nohighlight">\(k_{fold}\)</span> times, each time holding out a different one of the <span class="math notranslate nohighlight">\(k_{fold}\)</span> folds.</p>
<p>For example, we would apply the following steps if we chose a <span class="math notranslate nohighlight">\(k_{fold}\)</span> of five:</p>
<ol class="simple">
<li><p>Randomly divide the data set into five equally-sized folds.</p></li>
<li><p>Treat the fifth fold as the validation set and train the model on the first four folds.</p></li>
<li><p>Evaluate the model’s performance error on the fifth fold.</p></li>
<li><p>Repeat Steps 2 and 3 four more times, but each time treat a different fold as the validation set.</p></li>
<li><p>Calculate the model error for five-fold cross-validation by averaging the five error estimates from Step 3.</p></li>
</ol>
<p>This process is shown in the visualization below:</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/kfold.png"><img alt="../_images/kfold.png" src="../_images/kfold.png" style="height: 300px;" /></a>
</div>
<br>
<p>Imagine that we applied this process with the kNN algorithm and a <span class="math notranslate nohighlight">\(k_{knn}\)</span> of three. We would first divide our data into five folds, and train the kNN model on the first four folds using a <span class="math notranslate nohighlight">\(k_{knn}\)</span> of three. Then, we would calculate the accuracy of that model on the fifth fold. Next, we would train another kNN model (again using a <span class="math notranslate nohighlight">\(k_{knn}\)</span> of three) on folds one, two, three, and five, then calculate the accuracy of that model on the fourth fold. We would repeat this process five times, each time using a different one of the folds for validation. This would provide us with five separate estimates of the model’s accuracy, which we could average together for a final accuracy score.</p>
<p>Just as we tried several different values of <span class="math notranslate nohighlight">\(k_{knn}\)</span> in the previous section, we can perform cross validation with a grid of different values for our hyperparameter. Whichever value attains the best average accuracy score can be chosen as our final value of <span class="math notranslate nohighlight">\(k_{knn}\)</span>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">caret</span></code> package in R provides a framework for building and validating models with cross validation. The first step is to set up the conditions of the cross validation process with the <code class="docutils literal notranslate"><span class="pre">trainControl()</span></code> function, which uses the following syntax:</p>
<div class="admonition-syntax admonition">
<p class="admonition-title">Syntax</p>
<p><code class="docutils literal notranslate"><span class="pre">caret::trainControl(method,</span> <span class="pre">number)</span></code></p>
<ul class="simple">
<li><p><em>Required arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">method</span></code>: The method used to divide the data; there are many different approaches, but we will set it to “cv” for <strong>c</strong>ross <strong>v</strong>alidation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">number</span></code>: The number of folds (<em>i.e.</em>, <span class="math notranslate nohighlight">\(k_{fold}\)</span>).</p></li>
</ul>
</li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">cvConditions</span> <span class="o">&lt;-</span> <span class="nf">trainControl</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s">&quot;cv&quot;</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>What is this object for? We always want to build and compare multiple models under the same conditions. If we were evaluating two kNN models, one with a <span class="math notranslate nohighlight">\(k_{knn}\)</span> of three and another with a <span class="math notranslate nohighlight">\(k_{knn}\)</span> of ten, we would want to ensure that the models were trained and evaluated on the same set of observations so that they are directly comparable. The <code class="docutils literal notranslate"><span class="pre">cvConditions</span></code> object defines these conditions so that we are always consistent when training different models.</p>
<p>We will next use the <code class="docutils literal notranslate"><span class="pre">cvConditions</span></code> object with the <code class="docutils literal notranslate"><span class="pre">train()</span></code> function from <code class="docutils literal notranslate"><span class="pre">caret</span></code>, which actually performs the cross validation. This function uses the following syntax:</p>
<div class="admonition-syntax admonition">
<p class="admonition-title">Syntax</p>
<p><code class="docutils literal notranslate"><span class="pre">caret::train(y</span> <span class="pre">~</span> <span class="pre">x1</span> <span class="pre">+</span> <span class="pre">x2</span> <span class="pre">+</span> <span class="pre">…</span> <span class="pre">+</span> <span class="pre">xp,</span> <span class="pre">data,</span> <span class="pre">method</span> <span class="pre">=</span> <span class="pre">&quot;rf&quot;</span> <span class="pre">,</span> <span class="pre">trControl</span> <span class="pre">=</span> <span class="pre">trainControl(),</span> <span class="pre">tuneGrid</span> <span class="pre">=</span> <span class="pre">NULL)</span></code></p>
<ul class="simple">
<li><p><em>Required arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code>: The name of the dependent (<span class="math notranslate nohighlight">\(Y\)</span>) feature.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x1</span></code>, <code class="docutils literal notranslate"><span class="pre">x2</span></code>, …, <code class="docutils literal notranslate"><span class="pre">xp</span></code>:  The name of the first, second, and <span class="math notranslate nohighlight">\(p_{th}\)</span> independent feature. Note that if you just replace the names of the features with the wildcard character <code class="docutils literal notranslate"><span class="pre">.</span></code>, the model will be built using all of the features in the data set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: The name of the data frame with the <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">x1</span></code>, <code class="docutils literal notranslate"><span class="pre">x2</span></code>, and <code class="docutils literal notranslate"><span class="pre">xp</span></code> variables.</p></li>
</ul>
</li>
<li><p><em>Optional arguments</em></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">method</span></code>: The algorithm to apply. See <a class="reference external" href="https://topepo.github.io/caret/available-models.html">here</a> for the complete list of available models.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trControl</span></code>: A list defining the conditions of the training procedure.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tuneGrid</span></code>: A data frame with different values of the hyperparameter(s) to test.</p></li>
</ul>
</li>
</ul>
</div>
<p>In the code below, we apply this function to the <code class="docutils literal notranslate"><span class="pre">churn</span></code> data set. Within <code class="docutils literal notranslate"><span class="pre">train()</span></code>, we define the model with <code class="docutils literal notranslate"><span class="pre">churn</span></code> as the independent (<span class="math notranslate nohighlight">\(Y\)</span>) feature, and all the remaining features in the data set as dependent (<span class="math notranslate nohighlight">\(X\)</span>) features. Because we are using the kNN algorithm, we set <code class="docutils literal notranslate"><span class="pre">method</span></code> equal to <code class="docutils literal notranslate"><span class="pre">&quot;knn&quot;</span></code> (from the list <a class="reference external" href="https://topepo.github.io/caret/available-models.html">here</a>). We set <code class="docutils literal notranslate"><span class="pre">trControl</span></code> equal to the <code class="docutils literal notranslate"><span class="pre">cvConditions</span></code> object we created above to control how the cross validation is performed. Finally, we define a grid of different values for <span class="math notranslate nohighlight">\(k_{knn}\)</span> and pass that in to <code class="docutils literal notranslate"><span class="pre">tuneGrid</span></code>. Note that we set the random seed so that the process is replicable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">972945</span><span class="p">)</span>
<span class="n">knnCV</span> <span class="o">&lt;-</span> <span class="nf">train</span><span class="p">(</span><span class="n">churn</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> 
                 <span class="n">data</span> <span class="o">=</span> <span class="n">churnScaled</span><span class="p">,</span>
                 <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;knn&quot;</span><span class="p">,</span> 
                 <span class="n">trControl</span> <span class="o">=</span> <span class="n">cvConditions</span><span class="p">,</span> 
                 <span class="n">tuneGrid</span> <span class="o">=</span> <span class="nf">expand.grid</span><span class="p">(</span><span class="n">k</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">5</span><span class="p">,</span> <span class="m">10</span><span class="p">,</span> <span class="m">20</span><span class="p">)))</span>

<span class="n">knnCV</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>k-Nearest Neighbors 

3400 samples
  12 predictor
   2 classes: &#39;no&#39;, &#39;yes&#39; 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 2720, 2720, 2719, 2720, 2721 
Resampling results across tuning parameters:

  k   Accuracy   Kappa    
   1  0.8552832  0.3708154
   3  0.8844082  0.4207154
   5  0.8841206  0.3858950
  10  0.8820605  0.3480523
  20  0.8764739  0.2582296

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was k = 3.
</pre></div>
</div>
</div>
</div>
<p>How do we interpret this? In the output we see a small table with the following results:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>k</p></th>
<th class="text-align:center head"><p>Accuracy</p></th>
<th class="text-align:center head"><p>Kappa</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>1</p></td>
<td class="text-align:center"><p>0.8552832</p></td>
<td class="text-align:center"><p>0.3708154</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>3</p></td>
<td class="text-align:center"><p>0.8844082</p></td>
<td class="text-align:center"><p>0.4207154</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>5</p></td>
<td class="text-align:center"><p>0.8841206</p></td>
<td class="text-align:center"><p>0.3858950</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>10</p></td>
<td class="text-align:center"><p>0.8820605</p></td>
<td class="text-align:center"><p>0.3480523</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>20</p></td>
<td class="text-align:center"><p>0.8764739</p></td>
<td class="text-align:center"><p>0.2582296</p></td>
</tr>
</tbody>
</table>
<p>For each value of <span class="math notranslate nohighlight">\(k_{knn}\)</span>, the function performed five-fold cross validation, the results of which are shown in this table. For example, for a <span class="math notranslate nohighlight">\(k_{knn}\)</span> of one, <code class="docutils literal notranslate"><span class="pre">train()</span></code> built five different models on different folds of the data, and evaluated each one on the held-out fold. It then averaged those five accuracy estimates together for a final accuracy score of 85.53% (we will ignore kappa). As we can see from the table, <code class="docutils literal notranslate"><span class="pre">train()</span></code> determined that three is the optimal value of <span class="math notranslate nohighlight">\(k_{knn}\)</span>.</p>
</div>
<div class="section" id="holdout-sets">
<h2><span class="section-number">9.1.3. </span>Holdout Sets<a class="headerlink" href="#holdout-sets" title="Permalink to this headline">¶</a></h2>
<p>Finally, in addition to the train and validation sets, we always reserve a portion of our data as a <strong>holdout set</strong>. The purpose of the holdout set is to provide a final estimate of our model’s predictive accuracy on unseen data.</p>
<p>After we use the train and validation sets (or cross validation) to build and compare different models, we decide on a final model. We know how this model performs on the validation set, but this still does not provide an unbiased estimate for how our model will perform on unseen data. The reason for this is that although the model may not be directly trained on the observations in the validation set, the validation set was still used to tune the model’s hyperparameters. This means that the validation set had some influence on how the model was built. Consequently, it cannot provide a completely unbiased estimate for how the model will perform on observations it has never seen before. For this, we need to evaluate our final model on the holdout set.</p>
<p>It is important to emphasize that the holdout set should <em>never</em> influence the model building process. If you use the holdout set to make decisions about your model (which algorithm to use, the values of any hyperparameter(s), etc.), the holdout set can no longer provide an unbiased estimate of your model’s performance. Therefore, you should only look at the holdout set after you have decided on a final model.</p>
<p>For the churn data, we have held out a portion of the observations for the holdout set. These observations are saved in a data frame called <code class="docutils literal notranslate"><span class="pre">churnHoldout</span></code>; the first few observations are shown below.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html"><table>
<thead><tr><th scope=col>account_length</th><th scope=col>international_plan</th><th scope=col>voice_mail_plan</th><th scope=col>number_vmail_messages</th><th scope=col>total_day_minutes</th><th scope=col>total_day_calls</th><th scope=col>total_night_minutes</th><th scope=col>total_night_calls</th><th scope=col>total_intl_minutes</th><th scope=col>total_intl_calls</th><th scope=col>total_intl_charge</th><th scope=col>number_customer_service_calls</th><th scope=col>churn</th></tr></thead>
<tbody>
	<tr><td>147  </td><td>yes  </td><td>no   </td><td> 0   </td><td>157.0</td><td> 79  </td><td>211.8</td><td> 96  </td><td> 7.1 </td><td>6    </td><td>1.92 </td><td>0    </td><td>no   </td></tr>
	<tr><td> 85  </td><td>no   </td><td>yes  </td><td>27   </td><td>196.4</td><td>139  </td><td> 89.3</td><td> 75  </td><td>13.8 </td><td>4    </td><td>3.73 </td><td>1    </td><td>no   </td></tr>
	<tr><td> 57  </td><td>no   </td><td>yes  </td><td>39   </td><td>213.0</td><td>115  </td><td>182.7</td><td>115  </td><td> 9.5 </td><td>3    </td><td>2.57 </td><td>0    </td><td>no   </td></tr>
	<tr><td> 54  </td><td>no   </td><td>no   </td><td> 0   </td><td>134.3</td><td> 73  </td><td>102.1</td><td> 68  </td><td>14.7 </td><td>4    </td><td>3.97 </td><td>3    </td><td>no   </td></tr>
	<tr><td>121  </td><td>no   </td><td>yes  </td><td>30   </td><td>198.4</td><td>129  </td><td>181.2</td><td> 77  </td><td> 5.8 </td><td>3    </td><td>1.57 </td><td>3    </td><td>yes  </td></tr>
	<tr><td>116  </td><td>no   </td><td>yes  </td><td>34   </td><td>268.6</td><td> 83  </td><td>166.3</td><td>106  </td><td>11.6 </td><td>3    </td><td>3.13 </td><td>2    </td><td>no   </td></tr>
</tbody>
</table>
</div></div>
</div>
<br>
<p>To stay consistent, we need to (1) normalize the holdout data using the scaler we created in Section <a class="reference external" href="knn.html#applying-knn-in-r">Applying kNN in R</a>, and (2) convert the categorical variables into dummies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply min-max scaling to the holdout set</span>
<span class="n">churnHoldoutScaled</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">churnHoldout</span><span class="p">)</span>

<span class="c1"># Convert categorical variables in the holdout set to dummy variables</span>
<span class="n">churnHoldoutScaled</span><span class="o">$</span><span class="n">international_plan</span> <span class="o">&lt;-</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">churnHoldoutScaled</span><span class="o">$</span><span class="n">international_plan</span><span class="o">==</span><span class="s">&quot;yes&quot;</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">0</span><span class="p">)</span>
<span class="n">churnHoldoutScaled</span><span class="o">$</span><span class="n">voice_mail_plan</span> <span class="o">&lt;-</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">churnHoldoutScaled</span><span class="o">$</span><span class="n">voice_mail_plan</span><span class="o">==</span><span class="s">&quot;yes&quot;</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html"><table>
<thead><tr><th scope=col>account_length</th><th scope=col>international_plan</th><th scope=col>voice_mail_plan</th><th scope=col>number_vmail_messages</th><th scope=col>total_day_minutes</th><th scope=col>total_day_calls</th><th scope=col>total_night_minutes</th><th scope=col>total_night_calls</th><th scope=col>total_intl_minutes</th><th scope=col>total_intl_calls</th><th scope=col>total_intl_charge</th><th scope=col>number_customer_service_calls</th><th scope=col>churn</th></tr></thead>
<tbody>
	<tr><td>0.6033058</td><td>1        </td><td>0        </td><td>0.00     </td><td>0.4466572</td><td>0.4787879</td><td>0.5362025</td><td>0.5647059</td><td>0.355    </td><td>0.30     </td><td>0.3555556</td><td>0.0000000</td><td>no       </td></tr>
	<tr><td>0.3471074</td><td>0        </td><td>1        </td><td>0.54     </td><td>0.5587482</td><td>0.8424242</td><td>0.2260759</td><td>0.4411765</td><td>0.690    </td><td>0.20     </td><td>0.6907407</td><td>0.1111111</td><td>no       </td></tr>
	<tr><td>0.2314050</td><td>0        </td><td>1        </td><td>0.78     </td><td>0.6059744</td><td>0.6969697</td><td>0.4625316</td><td>0.6764706</td><td>0.475    </td><td>0.15     </td><td>0.4759259</td><td>0.0000000</td><td>no       </td></tr>
	<tr><td>0.2190083</td><td>0        </td><td>0        </td><td>0.00     </td><td>0.3820768</td><td>0.4424242</td><td>0.2584810</td><td>0.4000000</td><td>0.735    </td><td>0.20     </td><td>0.7351852</td><td>0.3333333</td><td>no       </td></tr>
	<tr><td>0.4958678</td><td>0        </td><td>1        </td><td>0.60     </td><td>0.5644381</td><td>0.7818182</td><td>0.4587342</td><td>0.4529412</td><td>0.290    </td><td>0.15     </td><td>0.2907407</td><td>0.3333333</td><td>yes      </td></tr>
	<tr><td>0.4752066</td><td>0        </td><td>1        </td><td>0.68     </td><td>0.7641536</td><td>0.5030303</td><td>0.4210127</td><td>0.6235294</td><td>0.580    </td><td>0.15     </td><td>0.5796296</td><td>0.2222222</td><td>no       </td></tr>
</tbody>
</table>
</div></div>
</div>
<br>
<p>Now we can use our final model to make predictions on the holdout set. Note that the object we created with the <code class="docutils literal notranslate"><span class="pre">train()</span></code> function, <code class="docutils literal notranslate"><span class="pre">knnCV</span></code>, automatically identifies the optimal hyperparameters and trains a final model on all of the data. We can view the details of this final model with <code class="docutils literal notranslate"><span class="pre">$finalModel</span></code>, as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">knnCV</span><span class="o">$</span><span class="n">finalModel</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3-nearest neighbor model
Training set outcome distribution:

  no  yes 
2912  488 
</pre></div>
</div>
</div>
</div>
<p>Because the optimal <span class="math notranslate nohighlight">\(k_{knn}\)</span> according to our cross validation was three, the final model is a <code class="docutils literal notranslate"><span class="pre">3-nearest</span> <span class="pre">neighbor</span> <span class="pre">model</span></code>.</p>
<p>Now we can use our final model to make predictions on the holdout set. We can do this using the same <code class="docutils literal notranslate"><span class="pre">predict()</span></code> function we used with linear regression. To do this we simply pass in our model object (<code class="docutils literal notranslate"><span class="pre">knnCV</span></code>) and the data we want to make predictions on (<code class="docutils literal notranslate"><span class="pre">churnHoldoutScaled</span></code>). The result is an atomic vector with the final model’s predictions on the holdout set. The predictions on the first few observations are shown in the output below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">finalModelPredictions</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">knnCV</span><span class="p">,</span> <span class="n">churnHoldoutScaled</span><span class="p">)</span>
<span class="n">finalModelPredictions</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><ol class=list-inline>
	<li>no</li>
	<li>no</li>
	<li>no</li>
	<li>no</li>
	<li>no</li>
</ol>

<details>
	<summary style=display:list-item;cursor:pointer>
		<strong>Levels</strong>:
	</summary>
	<ol class=list-inline>
		<li>'no'</li>
		<li>'yes'</li>
	</ol>
</details></div></div>
</div>
<p>Finally, we can calculate the accuracy of our final model on the holdout set using the <code class="docutils literal notranslate"><span class="pre">Accuracy()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">Accuracy</span><span class="p">(</span><span class="n">finalModelPredictions</span><span class="p">,</span> <span class="n">churnHoldoutScaled</span><span class="o">$</span><span class="n">churn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.898823529411765</div></div>
</div>
<p>This final accuracy measure provides an estimate for how well our model will perform on future observations.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            kernelName: "ir",
            path: "./09_model_eval"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="model_eval.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">9. </span>Model Evaluation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="performance_metrics.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9.2. </span>Performance Metrics</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By DSM Faculty<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>